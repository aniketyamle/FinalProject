{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "[![Seismic Data with salt CC-BY-SA Yilmaz](https://wiki.seg.org/images/1/14/Ch05_fig0-1.png)](https://wiki.seg.org/wiki/Salt-flank_reflections#/media/File:Ch05_fig0-1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "00833d394e3069216af171fd979c814e7e1e430d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "0e26e21ff39e8b2afc0003fec4e4f5269f61aa4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 128\n",
    "im_height = 128\n",
    "im_chan = 1\n",
    "path_train = '../input/train/'\n",
    "path_test = '../input/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89455be399a79910334eb76beafc40bcdab08f83"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71bc5858327bdf6c54a9f99c0ac68e27abfcd567",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img('../input/train/images/' + img_name + '.png')\n",
    "    img_mask = load_img('../input/train/masks/' + img_name + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97114b7b4f28347130dc3e44af5469d6efdf7ab1",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8f02165966489c8a21bb7127bb88e7cf607599d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    X_train[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf6ea42655fb0f5ee8994a65a7c3bef888ef1ae",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d66a11a8d8d48e16640307185062f5494c1f5b6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4716a2112dfb71c75e60bff90cb17836f78bf66",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e7c423ccf5145d6ac991dad85262540735e4dfe"
   },
   "source": [
    "# build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58e87797db5bb02b8f0ad6a0af6592e94f9f8b3f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((im_height, im_width, im_chan))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58969e2e3bdca3b94da4ebd4e513a83455adf00a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=30, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ab8516fb8ab135872dd4f4b895b5d76206df1fa"
   },
   "source": [
    "# Test Data\n",
    "First we'll get the test data. This takes a while, it's 18000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6d376a5ed9fa0ff708299f55a0a8ed8b8471137",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    sizes_test.append([x.shape[0], x.shape[1]])\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    X_test[n] = x\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2316034edcb7227673fd9b69264ca9c0d0e87f14",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af64790cdb7e5beb05fc34635cdf092124d7dc20",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in tnrange(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7da5a47444df98205dd7039223868b5d67f15400",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24defa25c00d0d91b38e559515e78c63f4d26e2b"
   },
   "source": [
    "We'll look at it again, just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6302c46fc76d8a43cb87d01c43c60c3c8f0ac98b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()\n",
    "tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "844cded40edc71652bc5b26852245e37f46f6448"
   },
   "source": [
    "# Prepare Submission\n",
    "We need to prepare the submission. A nice CSV with predictions. All of this is one to one from Ketil and does not differ from any of the other segmentation tasks. Check them out to improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6eaf7acaf4a0678638c5e40732c6533816777637",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
